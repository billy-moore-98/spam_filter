{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Text Message Spam Filter Using the Naive Bayes Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be building a spam filter using a multinomial Naive Bayes algorithm to classify whether incoming SMS messages are spam or not.\n",
    "\n",
    "The dataset used for both training and testing of the algorithm was created by Tiago A. Almeida and José María Gómez Hidalgo, and can be found at [The UCL Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The dataset contains SMS messages that are already classified as being spam or not.\n",
    "\n",
    "The Naive Bayes algorithm will assess whether each individual SMS message is spam by evaluating the word contents of the message. As the algorithm is 'Naive', it assumes there is conditional independence between the words in the message which allows the following probability relationships to be developed (full derivation of the relationships can be found in the Appendix):\n",
    "\n",
    "$$P(Spam|w_{1},w_{2},...w_{3}) \\ = \\ P(Spam) \\ \\Pi_{i=1}^{n} \\ P(w_{i}|Spam)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$w_{i}$ - the ith word of the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "The algorithm correctly predicts 98.7% of the test data. The messages which were wrongly predicted contained various elements which may have escaped the algorithm capabilities such as punctual emojis, abbreviations and acronyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from [this link](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition). It contains 2 columns, *Label* and *SMS*. *Label* details whether the message is spam or not and contains the following values:\n",
    "\n",
    "- *spam* - the message is spam\n",
    "- *ham* - the message is not spam\n",
    "\n",
    "*SMS* details the contents of the SMS message.\n",
    "\n",
    "The dataset was randomised and split in a 80/20 proportion into a Training and Test set. Below details the code which reads in the data, and cleans the strings so our data is ready for analysis and algorithm training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the SMS dataset file\n",
    "spam_sms = pd.read_csv(\"SMSSpamCollection\", sep='\\t', header=None, names=['Label', 'SMS']) \n",
    "spam_sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows and columns our data set has\n",
    "spam_sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of getting a spam  message from the dataset\n",
    "spam_sms['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that from the dataset, it is predicted that the probability of receiving a spam SMS message is 13%. In order to maintain this probability distribution when we split our dataset for training and test purposes, we will randomise the data set and split accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomise the entire dataset\n",
    "spam_sms_random = spam_sms.sample(frac=1, random_state=1)\n",
    "\n",
    "# Find the row index which encapsulated 80% of the data\n",
    "training_index = round(len(spam_sms_random) * 0.8)\n",
    "\n",
    "# Split the data into training and test data sets in a 80/20 split.\n",
    "training_data = spam_sms_random.iloc[:training_index].reset_index()\n",
    "test_data = spam_sms_random.iloc[training_index:].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having split the dataset accordingly, we should check that the spam and non-spam probabilities have been maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the *SMS* column, we can see that the message contents contain punctuation and uppercase letters which will affect consistency when applying the algorithm. To standardise all SMS messages, we will remove punctuation and convert all of the letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         Yep, by the pretty sculpture\n",
       "1        Yes, princess. Are you going to make me moan?\n",
       "2                           Welp apparently he retired\n",
       "3                                              Havent.\n",
       "4    I forgot 2 ask ü all smth.. There's a card on ...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['SMS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         yep  by the pretty sculpture\n",
       "1        yes  princess  are you going to make me moan \n",
       "2                           welp apparently he retired\n",
       "3                                              havent \n",
       "4    i forgot 2 ask ü all smth   there s a card on ...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all punctuation in the SMS column using the regex pattern \\W\n",
    "training_data['SMS'] = training_data['SMS'].str.replace(r'\\W', ' ')\n",
    "\n",
    "# Convert all letters to lowercase\n",
    "training_data['SMS'] = training_data['SMS'].str.lower()\n",
    "\n",
    "training_data['SMS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate all the probabilities required by the Naive Bayes algorithm, we need to transform the data into a more usable format.\n",
    "\n",
    "For illustrative purposes, at the moment our training dataset is formatted like this:\n",
    "\n",
    "| Label | SMS |\n",
    "| --- | --- |\n",
    "| Ham | yep by the pretty sculpture |\n",
    "| Ham | yes  princess  are you going to make me moan |\n",
    "| Ham | welp apparently he retired |\n",
    "| ... | ...|\n",
    "\n",
    "And we want to transform it to this:\n",
    "\n",
    "| Label | yep | yes | welp | by | princess | ... |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| Ham | 1 | 0 | 0 | 1 | 0 | ... |\n",
    "| Ham | 0 | 1 | 0 | 0 | 1 | ... |\n",
    "| Ham | 0 | 0 | 1 | 0 | 0 | ... |\n",
    "\n",
    "Essentially, we want columns of *all* the unique words used in the dataset with corresponding counts of the words per SMS message in each row. All of the unique words used in the dataset will be termed the *vocabulary*. This will help us to calculate the conditional probabilities for each word given a spam or non-spam message, which will be used in the classification algorithm.\n",
    "\n",
    "To do this we will create a dictionary with key-value pairs being each unique word in the vocabulary with a corresponding list of word counts for each SMS message in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each message string\n",
    "training_data['SMS'] = training_data['SMS'].str.split()\n",
    "\n",
    "# Initiate empty list to store all words used\n",
    "vocabulary = []\n",
    "\n",
    "# Loop through the SMS messages in the training dataset, and append the words to the vocabulary list\n",
    "for msg in training_data['SMS']:\n",
    "    for word in msg:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# Get the unique words in the vocabulary\n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate empty dictionary with keys being the unique words used in the vocabulary, corresponding value being a list of zeros\n",
    "# with length equal to the total number of SMS messages in the training dataset\n",
    "\n",
    "word_counts_per_sms = {word: [0] * len(training_data['SMS'])\n",
    "                       for word in vocabulary}\n",
    "\n",
    "# fill the value of each unique word key with the word count encountered in each SMS message\n",
    "for index, sms in enumerate(training_data['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engin</th>\n",
       "      <th>85555</th>\n",
       "      <th>proof</th>\n",
       "      <th>fromwrk</th>\n",
       "      <th>noon</th>\n",
       "      <th>requests</th>\n",
       "      <th>forth</th>\n",
       "      <th>xxx</th>\n",
       "      <th>hui</th>\n",
       "      <th>predicte</th>\n",
       "      <th>...</th>\n",
       "      <th>okey</th>\n",
       "      <th>someone</th>\n",
       "      <th>cab</th>\n",
       "      <th>chip</th>\n",
       "      <th>adore</th>\n",
       "      <th>09</th>\n",
       "      <th>chapel</th>\n",
       "      <th>80160</th>\n",
       "      <th>nok</th>\n",
       "      <th>pity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engin  85555  proof  fromwrk  noon  requests  forth  xxx  hui  predicte  \\\n",
       "0      0      0      0        0     0         0      0    0    0         0   \n",
       "1      0      0      0        0     0         0      0    0    0         0   \n",
       "2      0      0      0        0     0         0      0    0    0         0   \n",
       "3      0      0      0        0     0         0      0    0    0         0   \n",
       "4      0      0      0        0     0         0      0    0    0         0   \n",
       "\n",
       "   ...  okey  someone  cab  chip  adore  09  chapel  80160  nok  pity  \n",
       "0  ...     0        0    0     0      0   0       0      0    0     0  \n",
       "1  ...     0        0    0     0      0   0       0      0    0     0  \n",
       "2  ...     0        0    0     0      0   0       0      0    0     0  \n",
       "3  ...     0        0    0     0      0   0       0      0    0     0  \n",
       "4  ...     0        0    0     0      0   0       0      0    0     0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the unique word counts dictionary\n",
    "word_counts_per_sms = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts_per_sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>engin</th>\n",
       "      <th>85555</th>\n",
       "      <th>proof</th>\n",
       "      <th>fromwrk</th>\n",
       "      <th>noon</th>\n",
       "      <th>requests</th>\n",
       "      <th>forth</th>\n",
       "      <th>...</th>\n",
       "      <th>okey</th>\n",
       "      <th>someone</th>\n",
       "      <th>cab</th>\n",
       "      <th>chip</th>\n",
       "      <th>adore</th>\n",
       "      <th>09</th>\n",
       "      <th>chapel</th>\n",
       "      <th>80160</th>\n",
       "      <th>nok</th>\n",
       "      <th>pity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS  engin  \\\n",
       "0   1078   ham                  [yep, by, the, pretty, sculpture]      0   \n",
       "1   4028   ham  [yes, princess, are, you, going, to, make, me,...      0   \n",
       "2    958   ham                    [welp, apparently, he, retired]      0   \n",
       "3   4642   ham                                           [havent]      0   \n",
       "4   4674   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...      0   \n",
       "\n",
       "   85555  proof  fromwrk  noon  requests  forth  ...  okey  someone  cab  \\\n",
       "0      0      0        0     0         0      0  ...     0        0    0   \n",
       "1      0      0        0     0         0      0  ...     0        0    0   \n",
       "2      0      0        0     0         0      0  ...     0        0    0   \n",
       "3      0      0        0     0         0      0  ...     0        0    0   \n",
       "4      0      0        0     0         0      0  ...     0        0    0   \n",
       "\n",
       "   chip  adore  09  chapel  80160  nok  pity  \n",
       "0     0      0   0       0      0    0     0  \n",
       "1     0      0   0       0      0    0     0  \n",
       "2     0      0   0       0      0    0     0  \n",
       "3     0      0   0       0      0    0     0  \n",
       "4     0      0   0       0      0    0     0  \n",
       "\n",
       "[5 rows x 7786 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the unique word counts dictionary to the training data set\n",
    "training_set = pd.concat([training_data, word_counts_per_sms], axis=1)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Constants for the Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created the training data set with the corresponding word counts per message. In order to build the algorithm we require the following parameters:\n",
    "\n",
    "- $P(Spam)$ - the probability of a message being spam\n",
    "- $P(Ham)$ - the probability of a message being non-spam\n",
    "- $N_{spam}$ - total number of words in spam messages\n",
    "- $N_{ham}$ - total number of words in non-spam messages\n",
    "- $N_{vocab}$ - the number of unique words in the vocabulary\n",
    "- $\\alpha \\ = 1$ - constant for Laplace smoothing of conditional probability equations (see Appendix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set P(Spam) and P(Ham)\n",
    "spam_ham = training_set['Label'].value_counts(normalize=True)\n",
    "p_spam = spam_ham['spam']\n",
    "p_ham = spam_ham['ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set total number of words in spam and non-spam messages\n",
    "n_spam = 0\n",
    "n_ham = 0\n",
    "\n",
    "for msg in training_set[training_set['Label'] == 'spam']['SMS']:\n",
    "    n_spam += len(msg)\n",
    "for msg in training_set[training_set['Label'] == 'ham']['SMS']:\n",
    "    n_ham += len(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set total number of unique words in the vocabulary\n",
    "n_vocab = training_set.iloc[:,3:].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Laplace smoothing constant\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $P(Spam|w_{1},w_{2},...w_{3})$ we need to calculate:\n",
    "\n",
    "$$P(w_{i}|Spam) \\ = \\ \\frac{N_{w_{i}|Spam}+\\alpha}{N_{spam}+\\alpha N_{vocab}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $N_{w_{i}|Spam}$ - the number of times a word appears in spam messages\n",
    "\n",
    "And vice versa for non-spam messages.\n",
    "\n",
    "This is the  probability for each word appearing in spam or non-spam messages. It is therefore a constant for each word and spam/non-spam pair.\n",
    "\n",
    "To do this we will create 2 dictionaries for spam and non-spam messages containing key-value pairs of each unique word in the vocabulary with the corresponding number of times they are appear in spam/non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for spam and non-spam messages containing word counts for each word in the vocabulary\n",
    "unique_words_spam = {word: 0 for word in training_set.columns[3:]}\n",
    "unique_words_ham = {word: 0 for word in training_set.columns[3:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the spam and non-spam SMS messages in separate dataframes\n",
    "spam = training_set[training_set['Label'] == 'spam']\n",
    "ham = training_set[training_set['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the conditional probability for each word for spam and non-spam messages using the formula above\n",
    "for word in unique_words_spam:\n",
    "    unique_words_spam[word] = (spam[word].sum() + alpha) / (n_spam + alpha * n_vocab)\n",
    "\n",
    "for word in unique_words_ham:\n",
    "    unique_words_ham[word] = (ham[word].sum() + alpha) / (n_ham + alpha * n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below details the function code which encapsulated the Naive Bayes algorithm to classify whether an SMS message is spam or not.\n",
    "\n",
    "The function will then be used on the test data to discover the accuracy of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    \n",
    "    # Pre cleaning the SMS message string\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message) # Remove all punctuation from the string\n",
    "    message = message.lower() # Convert all letters to lowercase\n",
    "    message = message.split() # Split on whitespace to obtain list of words in the message\n",
    "    \n",
    "    # Initiate the probabilities used to classify whether the message is spam or not\n",
    "    # The variables are set equal to their respective total probability\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Loop through the words in the SMS message and obtain their corresponding conditional probability in the\n",
    "    # spam and non-spam dictionaries defined above\n",
    "    # If the word is not in the dictionaries, it is ignored as it is therefore not in the model vocabulary\n",
    "    \n",
    "    for word in message:\n",
    "        if word in unique_words_spam:\n",
    "            p_spam_given_message *= unique_words_spam[word]\n",
    "        if word in unique_words_ham:\n",
    "            p_ham_given_message *= unique_words_ham[word]\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Return relevant result\n",
    "    # If the probabilities for spam and non-spam are equal, then the result required human input\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predicted'] = test_data['SMS'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2131</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3418</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5393</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS predicted\n",
       "0   2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2   3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is: 98.7 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_data['SMS'].shape[0]\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print('The accuracy of the model is:', 100 * round(accuracy, 3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate where the model wrongly classified the SMS messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to return whether the model classified correctly or not\n",
    "def checker(row):\n",
    "    if row.Label == row.predicted:\n",
    "        return 'Correct'\n",
    "    else:\n",
    "        return 'Wrong'\n",
    "\n",
    "test_data['result'] = test_data.apply(checker, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114                                                                                                                                                                                                                                                                                                         Not heard from U4 a while. Call me now am here all night with just my knickers on. Make me beg for it like U did last time 01223585236 XX Luv Nikiyu4.net\n",
      "135                                                                                                                                                                                                                                                                                                   More people are dogging in your area now. Call 09090204448 and join like minded guys. Why not arrange 1 yourself. There's 1 this evening. A£1.50 minAPN LS278BB\n",
      "152                                                                                                                                                                                                                                                                                                                                                                                                                                 Unlimited texts. Limited minutes.\n",
      "159                                                                                                                                                                                                                                                                                                                                                                                                                                                      26th OF JULY\n",
      "284                                                                                                                                                                                                                                                                                                                                                                                                                                            Nokia phone is lovly..\n",
      "293    A Boy loved a gal. He propsd bt she didnt mind. He gv lv lttrs, Bt her frnds threw thm. Again d boy decided 2 aproach d gal , dt time a truck was speeding towards d gal. Wn it was about 2 hit d girl,d boy ran like hell n saved her. She asked 'hw cn u run so fast?' D boy replied \"Boost is d secret of my energy\" n instantly d girl shouted \"our energy\" n Thy lived happily 2gthr drinking boost evrydy Moral of d story:- I hv free msgs:D;): gud ni8\n",
      "302                                                                                                                                                                                                                                                                                                                                                                                                                                  No calls..messages..missed calls\n",
      "319                                                                                                                                                                                                                                                                                                                                                                 We have sent JD for Customer Service cum Accounts Executive to ur mail id, For details contact us\n",
      "504                                                                                                                                                                                                                                                                                                                                                        Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50\n",
      "546                                                                                                                                                                                                                                                                                                  Hi babe its Chloe, how r u? I was smashed on saturday night, it was great! How was your weekend? U been missing me? SP visionsms.com Text stop to stop 150p/text\n",
      "741                                                                                                                                                                                                                                                                                                       0A$NETWORKS allow companies to bill for SMS, so they are responsible for their \"suppliers\", just as a shop has to give a guarantee on what they sell. B. G.\n",
      "876                                                                                                                                                                                                                                                                                                                                                                                                                          RCT' THNQ Adrian for U text. Rgds Vatian\n",
      "885                                                                                                                                                                                                                                                                                                                                                                                                                                                     2/2 146tf150p\n",
      "953                                                                                                                                                                                                                                                                                                                            Hello. We need some posh birds and chaps to user trial prods for champneys. Can i put you down? I need your address and dob asap. Ta r\n",
      "Name: SMS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the SMS message contents of the messages the algorithm wrongly classified\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "print(test_data[test_data['result'] == 'Wrong']['SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the data above, we can see that the SMS messages that were wrongly classified have several features in common:\n",
    "\n",
    "- They contain punctual emoticons such as :D, :) or ;)\n",
    "- They contain abbreviations or slang terms such as ur (your), gv (give) or std (standard)\n",
    "\n",
    "Our model did not accomodate for these features, and this is possibly why they have been wrongly classified. To further develop the model we could:\n",
    "\n",
    "- Try to assign common slang terms to their corresponding word and incorporate them into the corresponding parameter\n",
    "- Try to make the model sensitive to letter case\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
